<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Memory management · CUDA.jl</title><meta name="title" content="Memory management · CUDA.jl"/><meta property="og:title" content="Memory management · CUDA.jl"/><meta property="twitter:title" content="Memory management · CUDA.jl"/><meta name="description" content="Documentation for CUDA.jl."/><meta property="og:description" content="Documentation for CUDA.jl."/><meta property="twitter:description" content="Documentation for CUDA.jl."/><meta property="og:url" content="https://cuda.juliagpu.org/stable/usage/memory/"/><meta property="twitter:url" content="https://cuda.juliagpu.org/stable/usage/memory/"/><link rel="canonical" href="https://cuda.juliagpu.org/stable/usage/memory/"/><script async src="https://www.googletagmanager.com/gtag/js?id=UA-154489943-2"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-154489943-2', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="CUDA.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">CUDA.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/introduction/">Introduction</a></li><li><a class="tocitem" href="../../tutorials/custom_structs/">Using custom structs</a></li><li><a class="tocitem" href="../../tutorials/performance/">Performance Tips</a></li></ul></li><li><span class="tocitem">Installation</span><ul><li><a class="tocitem" href="../../installation/overview/">Overview</a></li><li><a class="tocitem" href="../../installation/conditional/">Conditional use</a></li><li><a class="tocitem" href="../../installation/troubleshooting/">Troubleshooting</a></li></ul></li><li><span class="tocitem">Usage</span><ul><li><a class="tocitem" href="../overview/">Overview</a></li><li><a class="tocitem" href="../workflow/">Workflow</a></li><li><a class="tocitem" href="../array/">Array programming</a></li><li class="is-active"><a class="tocitem" href>Memory management</a><ul class="internal"><li><a class="tocitem" href="#Type-preserving-upload"><span>Type-preserving upload</span></a></li><li><a class="tocitem" href="#Unified-memory"><span>Unified memory</span></a></li><li><a class="tocitem" href="#Garbage-collection"><span>Garbage collection</span></a></li><li><a class="tocitem" href="#Batching-iterator"><span>Batching iterator</span></a></li></ul></li><li><a class="tocitem" href="../multitasking/">Tasks and threads</a></li><li><a class="tocitem" href="../multigpu/">Multiple GPUs</a></li></ul></li><li><span class="tocitem">Development</span><ul><li><a class="tocitem" href="../../development/profiling/">Benchmarking &amp; profiling</a></li><li><a class="tocitem" href="../../development/kernel/">Kernel programming</a></li><li><a class="tocitem" href="../../development/troubleshooting/">Troubleshooting</a></li><li><a class="tocitem" href="../../development/debugging/">Debugging</a></li></ul></li><li><span class="tocitem">API reference</span><ul><li><a class="tocitem" href="../../api/essentials/">Essentials</a></li><li><a class="tocitem" href="../../api/array/">Array programming</a></li><li><a class="tocitem" href="../../api/kernel/">Kernel programming</a></li><li><a class="tocitem" href="../../api/compiler/">Compiler</a></li></ul></li><li><span class="tocitem">Library reference</span><ul><li><a class="tocitem" href="../../lib/driver/">CUDA driver</a></li></ul></li><li><a class="tocitem" href="../../faq/">FAQ</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Usage</a></li><li class="is-active"><a href>Memory management</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Memory management</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaGPU/CUDA.jl/blob/master/docs/src/usage/memory.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Memory-management"><a class="docs-heading-anchor" href="#Memory-management">Memory management</a><a id="Memory-management-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-management" title="Permalink"></a></h1><p>A crucial aspect of working with a GPU is managing the data on it. The <code>CuArray</code> type is the primary interface for doing so: Creating a <code>CuArray</code> will allocate data on the GPU, copying elements to it will upload, and converting back to an <code>Array</code> will download values to the CPU:</p><pre><code class="language-julia hljs"># generate some data on the CPU
cpu = rand(Float32, 1024)

# allocate on the GPU
gpu = CuArray{Float32}(undef, 1024)

# copy from the CPU to the GPU
copyto!(gpu, cpu)

# download and verify
@test cpu == Array(gpu)</code></pre><p>A shorter way to accomplish these operations is to call the copy constructor, i.e. <code>CuArray(cpu)</code>.</p><h2 id="Type-preserving-upload"><a class="docs-heading-anchor" href="#Type-preserving-upload">Type-preserving upload</a><a id="Type-preserving-upload-1"></a><a class="docs-heading-anchor-permalink" href="#Type-preserving-upload" title="Permalink"></a></h2><p>In many cases, you might not want to convert your input data to a dense <code>CuArray</code>. For example, with array wrappers you will want to preserve that wrapper type on the GPU and only upload the contained data. The <a href="https://github.com/JuliaGPU/Adapt.jl">Adapt.jl</a> package does exactly that, and contains a list of rules on how to unpack and reconstruct types like array wrappers so that we can preserve the type when, e.g., uploading data to the GPU:</p><pre><code class="language-julia-repl hljs">julia&gt; cpu = Diagonal([1,2])     # wrapped data on the CPU
2×2 Diagonal{Int64,Array{Int64,1}}:
 1  ⋅
 ⋅  2

julia&gt; using Adapt

julia&gt; gpu = adapt(CuArray, cpu) # upload to the GPU, keeping the wrapper intact
2×2 Diagonal{Int64,CuArray{Int64,1,Nothing}}:
 1  ⋅
 ⋅  2</code></pre><p>Since this is a very common operation, the <code>cu</code> function conveniently does this for you:</p><pre><code class="language-julia-repl hljs">julia&gt; cu(cpu)
2×2 Diagonal{Float32,CuArray{Float32,1,Nothing}}:
 1.0   ⋅
  ⋅   2.0</code></pre><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>The <code>cu</code> function is opinionated and converts input most floating-point scalars to <code>Float32</code>. This is often a good call, as <code>Float64</code> and many other scalar types perform badly on the GPU. If this is unwanted, use <code>adapt</code> directly.</p></div></div><h2 id="Unified-memory"><a class="docs-heading-anchor" href="#Unified-memory">Unified memory</a><a id="Unified-memory-1"></a><a class="docs-heading-anchor-permalink" href="#Unified-memory" title="Permalink"></a></h2><p>The <code>CuArray</code> constructor and the <code>cu</code> function default to allocating device memory, which can be accessed only from the GPU. It is also possible to allocate unified memory, which is accessible from both the CPU and GPU with the driver taking care of data movement:</p><pre><code class="language-julia-repl hljs">julia&gt; cpu = [1,2]
2-element Vector{Int64}:
 1
 2

julia&gt; gpu = CuVector{Int,CUDA.UnifiedMemory}(cpu)
2-element CuArray{Int64, 1, CUDA.UnifiedMemory}:
 1
 2

julia&gt; gpu = cu(cpu; unified=true)
2-element CuArray{Int64, 1, CUDA.UnifiedMemory}:
 1
 2</code></pre><p>Using unified memory has several advantages: it is possible to allocate more memory than the GPU has available, and the memory can be accessed efficiently from the CPU, either directly or by wrapping the <code>CuArray</code> using an <code>Array</code>:</p><pre><code class="language-julia-repl hljs">julia&gt; gpu[1]  # no scalar indexing error!
1

julia&gt; cpu_again = unsafe_wrap(Array, gpu)
2-element Vector{Int64}:
 1
 2</code></pre><p>This may make it significantly easier to port code to the GPU, as you can incrementally port parts of your application without having to worry about executing CPU code, or triggering an <code>AbstractArray</code> fallback. It may come at a cost however, as unified memory needs to be paged in and out of the GPU memory, and cannot be allocated asynchronously. To alleviate this cost, CUDA.jl automatically prefetches unified memory when passing it to a kernel.</p><p>On recent systems (CUDA 12.2 with the open-source NVIDIA driver) it is also possible to do the reverse, and access CPU memory from the GPU without having to explicitly allocate unified memory using the <code>CuArray</code> constructor or <code>cu</code> function:</p><pre><code class="language-julia-repl hljs">julia&gt; cpu = [1,2];

julia&gt; gpu = unsafe_wrap(CuArray, cpu)
2-element CuArray{Int64, 1, CUDA.UnifiedMemory}:
 1
 2

julia&gt; gpu .+= 1;

julia&gt; cpu
2-element Vector{Int64}:
 2
 3</code></pre><p>Right now, CUDA.jl still defaults to allocating device memory, but this may change in the future. If you want to change the default behavior, you can set the <code>default_memory</code> preference to <code>unified</code> or <code>host</code> instead of <code>device</code>.</p><h2 id="Garbage-collection"><a class="docs-heading-anchor" href="#Garbage-collection">Garbage collection</a><a id="Garbage-collection-1"></a><a class="docs-heading-anchor-permalink" href="#Garbage-collection" title="Permalink"></a></h2><p>Instances of the <code>CuArray</code> type are managed by the Julia garbage collector. This means that they will be collected once they are unreachable, and the memory hold by it will be repurposed or freed. There is no need for manual memory management, just make sure your objects are not reachable (i.e., there are no instances or references).</p><h3 id="Memory-pool"><a class="docs-heading-anchor" href="#Memory-pool">Memory pool</a><a id="Memory-pool-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-pool" title="Permalink"></a></h3><p>Behind the scenes, a memory pool will hold on to your objects and cache the underlying memory to speed up future allocations. As a result, your GPU might seem to be running out of memory while it isn&#39;t. When memory pressure is high, the pool will automatically free cached objects:</p><pre><code class="language-julia-repl hljs">julia&gt; CUDA.pool_status()             # initial state
Effective GPU memory usage: 16.12% (2.537 GiB/15.744 GiB)
Memory pool usage: 0 bytes (0 bytes reserved)

julia&gt; a = CuArray{Int}(undef, 1024);   # allocate 8KB

julia&gt; CUDA.pool_status()
Effective GPU memory usage: 16.35% (2.575 GiB/15.744 GiB)
Memory pool usage: 8.000 KiB (32.000 MiB reserved)

julia&gt; a = nothing; GC.gc(true)

julia&gt; CUDA.pool_status()             # 8KB is now cached
Effective GPU memory usage: 16.34% (2.573 GiB/15.744 GiB)
Memory pool usage: 0 bytes (32.000 MiB reserved)
</code></pre><p>If for some reason you need all cached memory to be reclaimed, call <code>CUDA.reclaim()</code>:</p><pre><code class="language-julia-repl hljs">julia&gt; CUDA.reclaim()

julia&gt; CUDA.pool_status()
Effective GPU memory usage: 16.17% (2.546 GiB/15.744 GiB)
Memory pool usage: 0 bytes (0 bytes reserved)</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>It should never be required to manually reclaim memory before performing any high-level GPU array operation: Functionality that allocates should itself call into the memory pool and free any cached memory if necessary. It is a bug if that operation runs into an out-of-memory situation only if not manually reclaiming memory beforehand.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>If you need to disable the memory pool, e.g. because of incompatibility with certain CUDA APIs, set the environment variable <code>JULIA_CUDA_MEMORY_POOL</code> to <code>none</code> before importing CUDA.jl.</p></div></div><h3 id="Memory-limits"><a class="docs-heading-anchor" href="#Memory-limits">Memory limits</a><a id="Memory-limits-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-limits" title="Permalink"></a></h3><p>If you&#39;re sharing a GPU with other users or applications, you might want to limit how much memory is used. By default, CUDA.jl will configure the memory pool to use all available device memory. You can change this using two environment variables:</p><ul><li><code>JULIA_CUDA_SOFT_MEMORY_LIMIT</code>: This is an advisory limit, used to configure the memory pool. If you set this to a nonzero value, the memory pool will attempt to release cached memory until memory use falls below this limit. Note that this only happens at specific synchronization points, so memory use may temporarily exceed this limit. In addition, this limit is incompatible with <code>JULIA_CUDA_MEMORY_POOL=none</code>.</li><li><code>JULIA_CUDA_HARD_MEMORY_LIMIT</code>: This is a hard limit, checked before every allocation. On older versions of CUDA, before v12.2, this is a relatively expensive limit, so it is recommended to first try to use the soft limit.</li></ul><p>The value of these variables can be formatted as a numer of bytes, optionally followed by a unit, or as a percentage of the total device memory. Examples: <code>100M</code>, <code>50%</code>, <code>1.5GiB</code>, <code>10000</code>.</p><h3 id="Avoiding-GC-pressure"><a class="docs-heading-anchor" href="#Avoiding-GC-pressure">Avoiding GC pressure</a><a id="Avoiding-GC-pressure-1"></a><a class="docs-heading-anchor-permalink" href="#Avoiding-GC-pressure" title="Permalink"></a></h3><p>When your application performs a lot of memory operations, the time spent during GC might increase significantly. This happens more often than it does on the CPU because GPUs tend to have smaller memories and more frequently run out of it. When that happens, CUDA invokes the Julia garbage collector, which then needs to scan objects to see if they can be freed to get back some GPU memory.</p><p>To avoid having to depend on the Julia GC to free up memory, you can directly inform CUDA.jl when an allocation can be freed (or reused) by calling the <code>unsafe_free!</code> method. Once you&#39;ve done so, you cannot use that array anymore:</p><pre><code class="language-julia-repl hljs">julia&gt; a = CuArray([1])
1-element CuArray{Int64,1,Nothing}:
 1

julia&gt; CUDA.unsafe_free!(a)

julia&gt; a
1-element CuArray{Int64,1,Nothing}:
Error showing value of type CuArray{Int64,1,Nothing}:
ERROR: AssertionError: Use of freed memory</code></pre><h2 id="Batching-iterator"><a class="docs-heading-anchor" href="#Batching-iterator">Batching iterator</a><a id="Batching-iterator-1"></a><a class="docs-heading-anchor-permalink" href="#Batching-iterator" title="Permalink"></a></h2><p>If you are dealing with data sets that are too large to fit on the GPU all at once, you can use <code>CuIterator</code> to batch operations:</p><pre><code class="language-julia hljs">julia&gt; batches = [([1], [2]), ([3], [4])]

julia&gt; for (batch, (a,b)) in enumerate(CuIterator(batches))
         println(&quot;Batch $batch: &quot;, a .+ b)
       end
Batch 1: [3]
Batch 2: [7]</code></pre><p>For each batch, every argument (assumed to be an array-like) is uploaded to the GPU using the <code>adapt</code> mechanism from above. Afterwards, the memory is eagerly put back in the CUDA memory pool using <code>unsafe_free!</code> to lower GC pressure.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../array/">« Array programming</a><a class="docs-footer-nextpage" href="../multitasking/">Tasks and threads »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.0 on <span class="colophon-date" title="Monday 10 June 2024 12:38">Monday 10 June 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
