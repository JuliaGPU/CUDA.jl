<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>CUDA driver · CUDA.jl</title><script async src="https://www.googletagmanager.com/gtag/js?id=UA-154489943-2"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-154489943-2', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://cuda.juliagpu.org/stable/lib/driver/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="CUDA.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">CUDA.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/introduction/">Introduction</a></li><li><a class="tocitem" href="../../tutorials/custom_structs/">Using custom structs</a></li></ul></li><li><span class="tocitem">Installation</span><ul><li><a class="tocitem" href="../../installation/overview/">Overview</a></li><li><a class="tocitem" href="../../installation/conditional/">Conditional use</a></li><li><a class="tocitem" href="../../installation/troubleshooting/">Troubleshooting</a></li></ul></li><li><span class="tocitem">Usage</span><ul><li><a class="tocitem" href="../../usage/overview/">Overview</a></li><li><a class="tocitem" href="../../usage/workflow/">Workflow</a></li><li><a class="tocitem" href="../../usage/array/">Array programming</a></li><li><a class="tocitem" href="../../usage/memory/">Memory management</a></li><li><a class="tocitem" href="../../usage/multitasking/">Tasks and threads</a></li><li><a class="tocitem" href="../../usage/multigpu/">Multiple GPUs</a></li></ul></li><li><span class="tocitem">Development</span><ul><li><a class="tocitem" href="../../development/profiling/">Profiling</a></li><li><a class="tocitem" href="../../development/troubleshooting/">Troubleshooting</a></li></ul></li><li><span class="tocitem">API reference</span><ul><li><a class="tocitem" href="../../api/essentials/">Essentials</a></li><li><a class="tocitem" href="../../api/compiler/">Compiler</a></li><li><a class="tocitem" href="../../api/kernel/">Kernel programming</a></li><li><a class="tocitem" href="../../api/array/">Array programming</a></li></ul></li><li><span class="tocitem">Library reference</span><ul><li class="is-active"><a class="tocitem" href>CUDA driver</a><ul class="internal"><li><a class="tocitem" href="#Error-Handling"><span>Error Handling</span></a></li><li><a class="tocitem" href="#Version-Management"><span>Version Management</span></a></li><li><a class="tocitem" href="#Device-Management"><span>Device Management</span></a></li><li><a class="tocitem" href="#Context-Management"><span>Context Management</span></a></li><li><a class="tocitem" href="#Module-Management"><span>Module Management</span></a></li><li><a class="tocitem" href="#Memory-Management"><span>Memory Management</span></a></li><li><a class="tocitem" href="#Stream-Management"><span>Stream Management</span></a></li><li><a class="tocitem" href="#Event-Management"><span>Event Management</span></a></li><li><a class="tocitem" href="#Execution-Control"><span>Execution Control</span></a></li><li><a class="tocitem" href="#Profiler-Control"><span>Profiler Control</span></a></li><li><a class="tocitem" href="#Texture-Memory"><span>Texture Memory</span></a></li><li><a class="tocitem" href="#Occupancy-API"><span>Occupancy API</span></a></li><li><a class="tocitem" href="#Graph-Execution"><span>Graph Execution</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../../faq/">FAQ</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Library reference</a></li><li class="is-active"><a href>CUDA driver</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>CUDA driver</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaGPU/CUDA.jl/blob/master/docs/src/lib/driver.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="CUDA-driver"><a class="docs-heading-anchor" href="#CUDA-driver">CUDA driver</a><a id="CUDA-driver-1"></a><a class="docs-heading-anchor-permalink" href="#CUDA-driver" title="Permalink"></a></h1><p>This section lists the package&#39;s public functionality that directly corresponds to functionality of the CUDA driver API. In general, the abstractions stay close to those of the CUDA driver API, so for more information on certain library calls you can consult the <a href="http://docs.nvidia.com/cuda/cuda-driver-api/">CUDA driver API reference</a>.</p><p>The documentation is grouped according to the modules of the driver API.</p><h2 id="Error-Handling"><a class="docs-heading-anchor" href="#Error-Handling">Error Handling</a><a id="Error-Handling-1"></a><a class="docs-heading-anchor-permalink" href="#Error-Handling" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuError" href="#CUDA.CuError"><code>CUDA.CuError</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuError(code)
CuError(code, meta)</code></pre><p>Create a CUDA error object with error code <code>code</code>. The optional <code>meta</code> parameter indicates whether extra information, such as error logs, is known.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/error.jl#L6-L12">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.name-Tuple{CuError}" href="#CUDA.name-Tuple{CuError}"><code>CUDA.name</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">name(err::CuError)</code></pre><p>Gets the string representation of an error code.</p><pre><code class="language-julia-repl hljs">julia&gt; err = CuError(CUDA.cudaError_enum(1))
CuError(CUDA_ERROR_INVALID_VALUE)

julia&gt; name(err)
&quot;ERROR_INVALID_VALUE&quot;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/error.jl#L24-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.description-Tuple{CuError}" href="#CUDA.description-Tuple{CuError}"><code>CUDA.description</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">description(err::CuError)</code></pre><p>Gets the string description of an error code.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/error.jl#L43-L47">source</a></section></article><h2 id="Version-Management"><a class="docs-heading-anchor" href="#Version-Management">Version Management</a><a id="Version-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Version-Management" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CUDA.version-Tuple{}" href="#CUDA.version-Tuple{}"><code>CUDA.version</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">version()</code></pre><p>Returns the latest version of CUDA supported by the loaded driver.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/version.jl#L17-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.system_version-Tuple{}" href="#CUDA.system_version-Tuple{}"><code>CUDA.system_version</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">system_version()</code></pre><p>Returns the latest version of CUDA supported by the system driver.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/version.jl#L7-L11">source</a></section></article><h2 id="Device-Management"><a class="docs-heading-anchor" href="#Device-Management">Device Management</a><a id="Device-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Device-Management" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuDevice" href="#CUDA.CuDevice"><code>CUDA.CuDevice</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuDevice(ordinal::Integer)</code></pre><p>Get a handle to a compute device.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/devices.jl#L6-L10">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.devices" href="#CUDA.devices"><code>CUDA.devices</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">devices()</code></pre><p>Get an iterator for the compute devices.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/devices.jl#L137-L141">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.current_device" href="#CUDA.current_device"><code>CUDA.current_device</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">current_device()</code></pre><p>Returns the current device.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This is a low-level API, returning the current device as known to the CUDA driver. For most users, it is recommended to use the <a href="../../api/essentials/#CUDA.device"><code>device</code></a> method instead.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/devices.jl#L32-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.name-Tuple{CuDevice}" href="#CUDA.name-Tuple{CuDevice}"><code>CUDA.name</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">name(dev::CuDevice)</code></pre><p>Returns an identifier string for the device.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/devices.jl#L77-L81">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.totalmem-Tuple{CuDevice}" href="#CUDA.totalmem-Tuple{CuDevice}"><code>CUDA.totalmem</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">totalmem(dev::CuDevice)</code></pre><p>Returns the total amount of memory (in bytes) on the device.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/devices.jl#L105-L109">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.attribute" href="#CUDA.attribute"><code>CUDA.attribute</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">attribute(dev::CuDevice, code)</code></pre><p>Returns information about the device.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/devices.jl#L117-L121">source</a></section><section><div><pre><code class="nohighlight hljs">attribute(X, pool::CuMemoryPool, attr)</code></pre><p>Returns attribute <code>attr</code> about <code>pool</code>. The type of the returned value depends on the attribute, and as such must be passed as the <code>X</code> parameter.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/pool.jl#L69-L74">source</a></section><section><div><pre><code class="nohighlight hljs">attribute(X, ptr::Union{Ptr,CuPtr}, attr)</code></pre><p>Returns attribute <code>attr</code> about pointer <code>ptr</code>. The type of the returned value depends on the attribute, and as such must be passed as the <code>X</code> parameter.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L713-L718">source</a></section></article><p>Certain common attributes are exposed by additional convenience functions:</p><article class="docstring"><header><a class="docstring-binding" id="CUDA.capability-Tuple{CuDevice}" href="#CUDA.capability-Tuple{CuDevice}"><code>CUDA.capability</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">capability(dev::CuDevice)</code></pre><p>Returns the compute capability of the device.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/devices.jl#L182-L186">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.warpsize-Tuple{CuDevice}" href="#CUDA.warpsize-Tuple{CuDevice}"><code>CUDA.warpsize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">warpsize(dev::CuDevice)</code></pre><p>Returns the warp size (in threads) of the device.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/devices.jl#L175-L179">source</a></section></article><h2 id="Context-Management"><a class="docs-heading-anchor" href="#Context-Management">Context Management</a><a id="Context-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Context-Management" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuContext" href="#CUDA.CuContext"><code>CUDA.CuContext</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuContext(dev::CuDevice, flags=CTX_SCHED_AUTO)
CuContext(f::Function, ...)</code></pre><p>Create a CUDA context for device. A context on the GPU is analogous to a process on the CPU, with its own distinct address space and allocated resources. When a context is destroyed, the system cleans up the resources allocated to it.</p><p>When you are done using the context, call <a href="#CUDA.unsafe_destroy!-Tuple{CuContext}"><code>CUDA.unsafe_destroy!</code></a> to mark it for deletion, or use do-block syntax with this constructor.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L25-L36">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.unsafe_destroy!-Tuple{CuContext}" href="#CUDA.unsafe_destroy!-Tuple{CuContext}"><code>CUDA.unsafe_destroy!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">unsafe_destroy!(ctx::CuContext)</code></pre><p>Immediately destroy a context, freeing up all resources associated with it. This does not respect any users of the context, and might make other objects unusable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L120-L125">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.current_context" href="#CUDA.current_context"><code>CUDA.current_context</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">current_context()</code></pre><p>Returns the current context.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This is a low-level API, returning the current context as known to the CUDA driver. For most users, it is recommended to use the <a href="../../api/essentials/#CUDA.context"><code>context</code></a> method instead.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L82-L91">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.activate-Tuple{CuContext}" href="#CUDA.activate-Tuple{CuContext}"><code>CUDA.activate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">activate(ctx::CuContext)</code></pre><p>Binds the specified CUDA context to the calling CPU thread.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L192-L196">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.synchronize-Tuple{CuContext}" href="#CUDA.synchronize-Tuple{CuContext}"><code>CUDA.synchronize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">synchronize(ctx::Context)</code></pre><p>Block for the all operations on <code>ctx</code> to complete. This is a heavyweight operation, typically you only need to call <a href="#CUDA.synchronize-Tuple{CuContext}"><code>synchronize</code></a> which only synchronizes the stream associated with the current task.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L308-L314">source</a></section></article><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>device_synchronize</code>. Check Documenter&#39;s build log for details.</p></div></div><h3 id="Primary-Context-Management"><a class="docs-heading-anchor" href="#Primary-Context-Management">Primary Context Management</a><a id="Primary-Context-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Primary-Context-Management" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuPrimaryContext" href="#CUDA.CuPrimaryContext"><code>CUDA.CuPrimaryContext</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuPrimaryContext(dev::CuDevice)</code></pre><p>Create a primary CUDA context for a given device.</p><p>Each primary context is unique per device and is shared with CUDA runtime API. It is meant for interoperability with (applications using) the runtime API.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L13-L20">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuContext-Tuple{CuPrimaryContext}" href="#CUDA.CuContext-Tuple{CuPrimaryContext}"><code>CUDA.CuContext</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">CuContext(pctx::CuPrimaryContext)</code></pre><p>Retain the primary context on the GPU, returning a context compatible with the driver API. The primary context will be released when the returned driver context is finalized.</p><p>As these contexts are refcounted by CUDA, you should not call <a href="#CUDA.unsafe_destroy!-Tuple{CuContext}"><code>CUDA.unsafe_destroy!</code></a> on them but use <a href="#CUDA.unsafe_release!-Tuple{CuContext}"><code>CUDA.unsafe_release!</code></a> instead (available with do-block syntax as well).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L70-L79">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.isactive-Tuple{CuPrimaryContext}" href="#CUDA.isactive-Tuple{CuPrimaryContext}"><code>CUDA.isactive</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">isactive(pctx::CuPrimaryContext)</code></pre><p>Query whether a primary context is active.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L266-L270">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.flags-Tuple{CuPrimaryContext}" href="#CUDA.flags-Tuple{CuPrimaryContext}"><code>CUDA.flags</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">flags(pctx::CuPrimaryContext)</code></pre><p>Query the flags of a primary context.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L273-L277">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.setflags!-Tuple{CuPrimaryContext, CUDA.CUctx_flags_enum}" href="#CUDA.setflags!-Tuple{CuPrimaryContext, CUDA.CUctx_flags_enum}"><code>CUDA.setflags!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">setflags!(pctx::CuPrimaryContext)</code></pre><p>Set the flags of a primary context.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L280-L284">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.unsafe_reset!-Tuple{CuPrimaryContext}" href="#CUDA.unsafe_reset!-Tuple{CuPrimaryContext}"><code>CUDA.unsafe_reset!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">unsafe_reset!(pctx::CuPrimaryContext)</code></pre><p>Explicitly destroys and cleans up all resources associated with a device&#39;s primary context in the current process. Note that this forcibly invalidates all contexts derived from this primary context, and as a result outstanding resources might become invalid.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L241-L247">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.unsafe_release!-Tuple{CuContext}" href="#CUDA.unsafe_release!-Tuple{CuContext}"><code>CUDA.unsafe_release!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">CUDA.unsafe_release!(ctx::CuContext)</code></pre><p>Lower the refcount of a context, possibly freeing up all resources associated with it. This does not respect any users of the context, and might make other objects unusable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/context.jl#L212-L217">source</a></section></article><h2 id="Module-Management"><a class="docs-heading-anchor" href="#Module-Management">Module Management</a><a id="Module-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Module-Management" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuModule" href="#CUDA.CuModule"><code>CUDA.CuModule</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuModule(data, options::Dict{CUjit_option,Any})
CuModuleFile(path, options::Dict{CUjit_option,Any})</code></pre><p>Create a CUDA module from a data, or a file containing data. The data may be PTX code, a CUBIN, or a FATBIN.</p><p>The <code>options</code> is an optional dictionary of JIT options and their respective value.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module.jl#L9-L17">source</a></section></article><h3 id="Function-Management"><a class="docs-heading-anchor" href="#Function-Management">Function Management</a><a id="Function-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Function-Management" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuFunction" href="#CUDA.CuFunction"><code>CUDA.CuFunction</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuFunction(mod::CuModule, name::String)</code></pre><p>Acquires a function handle from a named function in a module.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/function.jl#L7-L11">source</a></section></article><h3 id="Global-Variable-Management"><a class="docs-heading-anchor" href="#Global-Variable-Management">Global Variable Management</a><a id="Global-Variable-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Global-Variable-Management" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuGlobal" href="#CUDA.CuGlobal"><code>CUDA.CuGlobal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuGlobal{T}(mod::CuModule, name::String)</code></pre><p>Acquires a typed global variable handle from a named global in a module.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/global.jl#L11-L15">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.eltype-Tuple{CuGlobal}" href="#Base.eltype-Tuple{CuGlobal}"><code>Base.eltype</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">eltype(var::CuGlobal)</code></pre><p>Return the element type of a global variable object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/global.jl#L37-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.getindex-Tuple{CuGlobal}" href="#Base.getindex-Tuple{CuGlobal}"><code>Base.getindex</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Base.getindex(var::CuGlobal)</code></pre><p>Return the current value of a global variable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/global.jl#L44-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.setindex!-Union{Tuple{T}, Tuple{CuGlobal{T}, T}} where T" href="#Base.setindex!-Union{Tuple{T}, Tuple{CuGlobal{T}, T}} where T"><code>Base.setindex!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Base.setindex(var::CuGlobal{T}, val::T)</code></pre><p>Set the value of a global variable to <code>val</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/global.jl#L60-L64">source</a></section></article><h3 id="Linker"><a class="docs-heading-anchor" href="#Linker">Linker</a><a id="Linker-1"></a><a class="docs-heading-anchor-permalink" href="#Linker" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuLink" href="#CUDA.CuLink"><code>CUDA.CuLink</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuLink()</code></pre><p>Creates a pending JIT linker invocation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/linker.jl#L7-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.add_data!" href="#CUDA.add_data!"><code>CUDA.add_data!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">add_data!(link::CuLink, name::String, code::String)</code></pre><p>Add PTX code to a pending link operation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/linker.jl#L61-L65">source</a></section><section><div><pre><code class="nohighlight hljs">add_data!(link::CuLink, name::String, data::Vector{UInt8}, type::CUjitInputType)</code></pre><p>Add object code to a pending link operation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/linker.jl#L83-L87">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.add_file!" href="#CUDA.add_file!"><code>CUDA.add_file!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">add_file!(link::CuLink, path::String, typ::CUjitInputType)</code></pre><p>Add data from a file to a link operation. The argument <code>typ</code> indicates the type of the contained data.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/linker.jl#L102-L107">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuLinkImage" href="#CUDA.CuLinkImage"><code>CUDA.CuLinkImage</code></a> — <span class="docstring-category">Type</span></header><section><div><p>The result of a linking operation.</p><p>This object keeps its parent linker object alive, as destroying a linker destroys linked images too.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/linker.jl#L114-L119">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.complete" href="#CUDA.complete"><code>CUDA.complete</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">complete(link::CuLink)</code></pre><p>Complete a pending linker invocation, returning an output image.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/linker.jl#L126-L130">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuModule-Tuple{CuLinkImage, Vararg{Any, N} where N}" href="#CUDA.CuModule-Tuple{CuLinkImage, Vararg{Any, N} where N}"><code>CUDA.CuModule</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">CuModule(img::CuLinkImage, ...)</code></pre><p>Create a CUDA module from a completed linking operation. Options from <code>CuModule</code> apply.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/module/linker.jl#L157-L161">source</a></section></article><h2 id="Memory-Management"><a class="docs-heading-anchor" href="#Memory-Management">Memory Management</a><a id="Memory-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-Management" title="Permalink"></a></h2><p>Three kinds of memory buffers can be allocated: device memory, host memory, and unified memory. Each of these buffers can be allocated by calling <code>alloc</code> with the type of buffer as first argument, and freed by calling <code>free</code>. Certain buffers have specific methods defined.</p><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.DeviceBuffer" href="#CUDA.Mem.DeviceBuffer"><code>CUDA.Mem.DeviceBuffer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Mem.DeviceBuffer
Mem.Device</code></pre><p>A buffer of device memory residing on the GPU.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L38-L43">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.alloc-Tuple{Type{CUDA.Mem.DeviceBuffer}, Integer}" href="#CUDA.Mem.alloc-Tuple{Type{CUDA.Mem.DeviceBuffer}, Integer}"><code>CUDA.Mem.alloc</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Mem.alloc(DeviceBuffer, bytesize::Integer;
          [async=false], [stream::CuStream], [pool::CuMemoryPool])</code></pre><p>Allocate <code>bytesize</code> bytes of memory on the device. This memory is only accessible on the GPU, and requires explicit calls to <code>unsafe_copyto!</code>, which wraps <code>cuMemcpy</code>, for access on the CPU.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L62-L69">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.HostBuffer" href="#CUDA.Mem.HostBuffer"><code>CUDA.Mem.HostBuffer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Mem.HostBuffer
Mem.Host</code></pre><p>A buffer of pinned memory on the CPU, possibly accessible on the GPU.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L105-L110">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.alloc-Tuple{Type{CUDA.Mem.HostBuffer}, Integer, Any}" href="#CUDA.Mem.alloc-Tuple{Type{CUDA.Mem.HostBuffer}, Integer, Any}"><code>CUDA.Mem.alloc</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Mem.alloc(HostBuffer, bytesize::Integer, [flags])</code></pre><p>Allocate <code>bytesize</code> bytes of page-locked memory on the host. This memory is accessible from the CPU, and makes it possible to perform faster memory copies to the GPU. Furthermore, if <code>flags</code> is set to <code>HOSTALLOC_DEVICEMAP</code> the memory is also accessible from the GPU. These accesses are direct, and go through the PCI bus. If <code>flags</code> is set to <code>HOSTALLOC_PORTABLE</code>, the memory is considered mapped by all CUDA contexts, not just the one that created the memory, which is useful if the memory needs to be accessed from multiple devices. Multiple <code>flags</code> can be set at one time using a bytewise <code>OR</code>:</p><pre><code class="nohighlight hljs">flags = HOSTALLOC_PORTABLE | HOSTALLOC_DEVICEMAP</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L140-L153">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.register-Tuple{Type{CUDA.Mem.HostBuffer}, Ptr, Integer, Any}" href="#CUDA.Mem.register-Tuple{Type{CUDA.Mem.HostBuffer}, Ptr, Integer, Any}"><code>CUDA.Mem.register</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Mem.register(HostBuffer, ptr::Ptr, bytesize::Integer, [flags])</code></pre><p>Page-lock the host memory pointed to by <code>ptr</code>. Subsequent transfers to and from devices will be faster, and can be executed asynchronously. If the <code>HOSTREGISTER_DEVICEMAP</code> flag is specified, the buffer will also be accessible directly from the GPU. These accesses are direct, and go through the PCI bus. If the <code>HOSTREGISTER_PORTABLE</code> flag is specified, any CUDA context can access the memory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L168-L176">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.unregister-Tuple{CUDA.Mem.HostBuffer}" href="#CUDA.Mem.unregister-Tuple{CUDA.Mem.HostBuffer}"><code>CUDA.Mem.unregister</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Mem.unregister(HostBuffer)</code></pre><p>Unregisters a memory range that was registered with <a href="#CUDA.Mem.register-Tuple{Type{CUDA.Mem.HostBuffer}, Ptr, Integer, Any}"><code>Mem.register</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L185-L189">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.UnifiedBuffer" href="#CUDA.Mem.UnifiedBuffer"><code>CUDA.Mem.UnifiedBuffer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Mem.UnifiedBuffer
Mem.Unified</code></pre><p>A managed buffer that is accessible on both the CPU and GPU.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L204-L209">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.alloc-Tuple{Type{CUDA.Mem.UnifiedBuffer}, Integer, CUDA.CUmemAttach_flags_enum}" href="#CUDA.Mem.alloc-Tuple{Type{CUDA.Mem.UnifiedBuffer}, Integer, CUDA.CUmemAttach_flags_enum}"><code>CUDA.Mem.alloc</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Mem.alloc(UnifiedBuffer, bytesize::Integer, [flags::CUmemAttach_flags])</code></pre><p>Allocate <code>bytesize</code> bytes of unified memory. This memory is accessible from both the CPU and GPU, with the CUDA driver automatically copying upon first access.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L231-L236">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.prefetch-Tuple{CUDA.Mem.UnifiedBuffer, Integer}" href="#CUDA.Mem.prefetch-Tuple{CUDA.Mem.UnifiedBuffer, Integer}"><code>CUDA.Mem.prefetch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">prefetch(::UnifiedBuffer, [bytes::Integer]; [device::CuDevice], [stream::CuStream])</code></pre><p>Prefetches memory to the specified destination device.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L255-L259">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Mem.advise-Tuple{CUDA.Mem.UnifiedBuffer, CUDA.CUmem_advise_enum, Integer}" href="#CUDA.Mem.advise-Tuple{CUDA.Mem.UnifiedBuffer, CUDA.CUmem_advise_enum, Integer}"><code>CUDA.Mem.advise</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">advise(::UnifiedBuffer, advice::CUDA.CUmem_advise, [bytes::Integer]; [device::CuDevice])</code></pre><p>Advise about the usage of a given memory range.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L269-L273">source</a></section></article><p>To work with these buffers, you need to <code>convert</code> them to a <code>Ptr</code> or <code>CuPtr</code>. Several methods then work with these raw pointers:</p><h3 id="Memory-info"><a class="docs-heading-anchor" href="#Memory-info">Memory info</a><a id="Memory-info-1"></a><a class="docs-heading-anchor-permalink" href="#Memory-info" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="CUDA.available_memory" href="#CUDA.available_memory"><code>CUDA.available_memory</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">available_memory()</code></pre><p>Returns the available amount of memory (in bytes), available for allocation by the CUDA context.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L696-L700">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.total_memory" href="#CUDA.total_memory"><code>CUDA.total_memory</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">total_memory()</code></pre><p>Returns the total amount of memory (in bytes), available for allocation by the CUDA context.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/memory.jl#L703-L707">source</a></section></article><h2 id="Stream-Management"><a class="docs-heading-anchor" href="#Stream-Management">Stream Management</a><a id="Stream-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Stream-Management" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuStream" href="#CUDA.CuStream"><code>CUDA.CuStream</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuStream(; flags=STREAM_DEFAULT, priority=nothing)</code></pre><p>Create a CUDA stream.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/stream.jl#L7-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.isdone-Tuple{CuStream}" href="#CUDA.isdone-Tuple{CuStream}"><code>CUDA.isdone</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">isdone(s::CuStream)</code></pre><p>Return <code>false</code> if a stream is busy (has task running or queued) and <code>true</code> if that stream is free.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/stream.jl#L94-L99">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.priority_range" href="#CUDA.priority_range"><code>CUDA.priority_range</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">priority_range()</code></pre><p>Return the valid range of stream priorities as a <code>StepRange</code> (with step size  1). The lower bound of the range denotes the least priority (typically 0), with the upper bound representing the greatest possible priority (typically -1).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/stream.jl#L165-L171">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.priority" href="#CUDA.priority"><code>CUDA.priority</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">priority_range(s::CuStream)</code></pre><p>Return the priority of a stream <code>s</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/stream.jl#L181-L185">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.synchronize-Tuple{CuStream}" href="#CUDA.synchronize-Tuple{CuStream}"><code>CUDA.synchronize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">synchronize([stream::CuStream])</code></pre><p>Wait until <code>stream</code> has finished executing, with <code>stream</code> defaulting to the stream associated with the current Julia task.</p><p>See also: <a href="../../api/kernel/#CUDA.device_synchronize"><code>device_synchronize</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/stream.jl#L111-L118">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.@sync" href="#CUDA.@sync"><code>CUDA.@sync</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@sync ex</code></pre><p>Run expression <code>ex</code> and synchronize the GPU afterwards.</p><p>See also: <a href="#CUDA.synchronize-Tuple{CuContext}"><code>synchronize</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/src/utilities.jl#L1-L7">source</a></section></article><p>For specific use cases, special streams are available:</p><article class="docstring"><header><a class="docstring-binding" id="CUDA.default_stream" href="#CUDA.default_stream"><code>CUDA.default_stream</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">default_stream()</code></pre><p>Return the default stream.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>It is generally better to use <code>stream()</code> to get a stream object that&#39;s local to the current task. That way, operations scheduled in other tasks can overlap.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/stream.jl#L39-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.legacy_stream" href="#CUDA.legacy_stream"><code>CUDA.legacy_stream</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">legacy_stream()</code></pre><p>Return a special object to use use an implicit stream with legacy synchronization behavior.</p><p>You can use this stream to perform operations that should block on all streams (with the exception of streams created with <code>STREAM_NON_BLOCKING</code>). This matches the old pre-CUDA 7 global stream behavior.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/stream.jl#L51-L59">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.per_thread_stream" href="#CUDA.per_thread_stream"><code>CUDA.per_thread_stream</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">per_thread_stream()</code></pre><p>Return a special object to use an implicit stream with per-thread synchronization behavior. This stream object is normally meant to be used with APIs that do not have per-thread versions of their APIs (i.e. without a <code>ptsz</code> or <code>ptds</code> suffix).</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>It is generally not needed to use this type of stream. With CUDA.jl, each task already gets its own non-blocking stream, and multithreading in Julia is typically accomplished using tasks.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/stream.jl#L62-L74">source</a></section></article><h2 id="Event-Management"><a class="docs-heading-anchor" href="#Event-Management">Event Management</a><a id="Event-Management-1"></a><a class="docs-heading-anchor-permalink" href="#Event-Management" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuEvent" href="#CUDA.CuEvent"><code>CUDA.CuEvent</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuEvent()</code></pre><p>Create a new CUDA event.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/events.jl#L8-L12">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.record" href="#CUDA.record"><code>CUDA.record</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">record(e::CuEvent, [stream::CuStream])</code></pre><p>Record an event on a stream.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/events.jl#L37-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.synchronize-Tuple{CuEvent}" href="#CUDA.synchronize-Tuple{CuEvent}"><code>CUDA.synchronize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">synchronize(e::CuEvent)</code></pre><p>Waits for an event to complete.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/events.jl#L45-L49">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.isdone-Tuple{CuEvent}" href="#CUDA.isdone-Tuple{CuEvent}"><code>CUDA.isdone</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">isdone(e::CuEvent)</code></pre><p>Return <code>false</code> if there is outstanding work preceding the most recent call to <code>record(e)</code> and <code>true</code> if all captured work has been completed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/events.jl#L81-L86">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.wait-Tuple{CuEvent}" href="#CUDA.wait-Tuple{CuEvent}"><code>CUDA.wait</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">wait(e::CuEvent, [stream::CuStream])</code></pre><p>Make a stream wait on a event. This only makes the stream wait, and not the host; use <a href="#CUDA.synchronize-Tuple{CuEvent}"><code>synchronize(::CuEvent)</code></a> for that.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/events.jl#L98-L103">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.elapsed" href="#CUDA.elapsed"><code>CUDA.elapsed</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">elapsed(start::CuEvent, stop::CuEvent)</code></pre><p>Computes the elapsed time between two events (in seconds).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/events.jl#L107-L111">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.@elapsed" href="#CUDA.@elapsed"><code>CUDA.@elapsed</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@elapsed ex</code></pre><p>A macro to evaluate an expression, discarding the resulting value, instead returning the number of seconds it took to execute on the GPU, as a floating-point number.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/events.jl#L118-L123">source</a></section></article><h2 id="Execution-Control"><a class="docs-heading-anchor" href="#Execution-Control">Execution Control</a><a id="Execution-Control-1"></a><a class="docs-heading-anchor-permalink" href="#Execution-Control" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuDim3" href="#CUDA.CuDim3"><code>CUDA.CuDim3</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuDim3(x)

CuDim3((x,))
CuDim3((x, y))
CuDim3((x, y, x))</code></pre><p>A type used to specify dimensions, consisting of 3 integers for respectively the <code>x</code>, <code>y</code> and <code>z</code> dimension. Unspecified dimensions default to <code>1</code>.</p><p>Often accepted as argument through the <code>CuDim</code> type alias, eg. in the case of <a href="#CUDA.cudacall"><code>cudacall</code></a> or <a href="#CUDA.launch"><code>CUDA.launch</code></a>, allowing to pass dimensions as a plain integer or a tuple without having to construct an explicit <code>CuDim3</code> object.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/types.jl#L3-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.cudacall" href="#CUDA.cudacall"><code>CUDA.cudacall</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">cudacall(f, types, values...; blocks::CuDim, threads::CuDim,
         cooperative=false, shmem=0, stream=stream())</code></pre><p><code>ccall</code>-like interface for launching a CUDA function <code>f</code> on a GPU.</p><p>For example:</p><pre><code class="nohighlight hljs">vadd = CuFunction(md, &quot;vadd&quot;)
a = rand(Float32, 10)
b = rand(Float32, 10)
ad = Mem.alloc(DeviceBuffer, 10*sizeof(Float32))
unsafe_copyto!(ad, convert(Ptr{Cvoid}, a), 10*sizeof(Float32)))
bd = Mem.alloc(DeviceBuffer, 10*sizeof(Float32))
unsafe_copyto!(bd, convert(Ptr{Cvoid}, b), 10*sizeof(Float32)))
c = zeros(Float32, 10)
cd = Mem.alloc(DeviceBuffer, 10*sizeof(Float32))

cudacall(vadd, (CuPtr{Cfloat},CuPtr{Cfloat},CuPtr{Cfloat}), ad, bd, cd; threads=10)
unsafe_copyto!(convert(Ptr{Cvoid}, c), cd, 10*sizeof(Float32)))</code></pre><p>The <code>blocks</code> and <code>threads</code> arguments control the launch configuration, and should both consist of either an integer, or a tuple of 1 to 3 integers (omitted dimensions default to 1). The <code>types</code> argument can contain both a tuple of types, and a tuple type, the latter being slightly faster.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/execution.jl#L102-L127">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.launch" href="#CUDA.launch"><code>CUDA.launch</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">launch(f::CuFunction; args...; blocks::CuDim=1, threads::CuDim=1,
       cooperative=false, shmem=0, stream=stream())</code></pre><p>Low-level call to launch a CUDA function <code>f</code> on the GPU, using <code>blocks</code> and <code>threads</code> as respectively the grid and block configuration. Dynamic shared memory is allocated according to <code>shmem</code>, and the kernel is launched on stream <code>stream</code>.</p><p>Arguments to a kernel should either be bitstype, in which case they will be copied to the internal kernel parameter buffer, or a pointer to device memory.</p><p>This is a low-level call, prefer to use <a href="#CUDA.cudacall"><code>cudacall</code></a> instead.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/execution.jl#L39-L51">source</a></section><section><div><pre><code class="nohighlight hljs">launch(exec::CuGraphExec, [stream::CuStream])</code></pre><p>Launches an executable graph, by default in the currently-active stream.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/graph.jl#L120-L124">source</a></section></article><h2 id="Profiler-Control"><a class="docs-heading-anchor" href="#Profiler-Control">Profiler Control</a><a id="Profiler-Control-1"></a><a class="docs-heading-anchor-permalink" href="#Profiler-Control" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="CUDA.@profile" href="#CUDA.@profile"><code>CUDA.@profile</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">@profile ex</code></pre><p>Run expressions while activating the CUDA profiler.</p><p>Note that this API is used to programmatically control the profiling granularity by allowing profiling to be done only on selective pieces of code. It does not perform any profiling on itself, you need external tools for that.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/profile.jl#L3-L11">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Profile.start" href="#CUDA.Profile.start"><code>CUDA.Profile.start</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">start()</code></pre><p>Enables profile collection by the active profiling tool for the current context. If profiling is already enabled, then this call has no effect.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/profile.jl#L59-L64">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.Profile.stop" href="#CUDA.Profile.stop"><code>CUDA.Profile.stop</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">stop()</code></pre><p>Disables profile collection by the active profiling tool for the current context. If profiling is already disabled, then this call has no effect.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/profile.jl#L81-L86">source</a></section></article><h2 id="Texture-Memory"><a class="docs-heading-anchor" href="#Texture-Memory">Texture Memory</a><a id="Texture-Memory-1"></a><a class="docs-heading-anchor-permalink" href="#Texture-Memory" title="Permalink"></a></h2><p>Textures are represented by objects of type <code>CuTexture</code> which are bound to some underlying memory, either <code>CuArray</code>s or <code>CuTextureArray</code>s:</p><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuTexture" href="#CUDA.CuTexture"><code>CUDA.CuTexture</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuTexture{T,N,P}</code></pre><p><code>N</code>-dimensional texture object with elements of type <code>T</code>. These objects do not store data themselves, but are bounds to another source of device memory. Texture objects can be passed to CUDA kernels, where they will be accessible through the <a href="../../api/kernel/#CUDA.CuDeviceTexture"><code>CuDeviceTexture</code></a> type.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Experimental API. Subject to change without deprecation.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/src/texture.jl#L140-L149">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuTexture-Tuple{Any}" href="#CUDA.CuTexture-Tuple{Any}"><code>CUDA.CuTexture</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">CuTexture{T,N,P}(parent::P; address_mode, filter_mode, normalized_coordinates)</code></pre><p>Construct a <code>N</code>-dimensional texture object with elements of type <code>T</code> as stored in <code>parent</code>.</p><p>Several keyword arguments alter the behavior of texture objects:</p><ul><li><code>address_mode</code> (wrap, <em>clamp</em>, mirror): how out-of-bounds values are accessed. Can be specified as a value for all dimensions, or as a tuple of <code>N</code> entries.</li><li><code>interpolation</code> (<em>nearest neighbour</em>, linear, bilinear): how non-integral indices are fetched. Nearest-neighbour fetches a single value, others interpolate between multiple.</li><li><code>normalized_coordinates</code> (true, <em>false</em>): whether indices are expected to fall in the normalized <code>[0:1)</code> range.</li></ul><p>!!! warning Experimental API. Subject to change without deprecation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/src/texture.jl#L159-L174">source</a></section><section><div><pre><code class="nohighlight hljs">CuTexture(x::CuTextureArray{T,N})</code></pre><p>Create a <code>N</code>-dimensional texture object withelements of type <code>T</code> that will be read from <code>x</code>.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Experimental API. Subject to change without deprecation.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/src/texture.jl#L289-L296">source</a></section><section><div><pre><code class="nohighlight hljs">CuTexture(x::CuArray{T,N})</code></pre><p>Create a <code>N</code>-dimensional texture object that reads from a <code>CuArray</code>.</p><p>Note that it is necessary the their memory is well aligned and strided (good pitch). Currently, that is not being enforced.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Experimental API. Subject to change without deprecation.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/src/texture.jl#L300-L310">source</a></section></article><p>You can create <code>CuTextureArray</code> objects from both host and device memory:</p><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuTextureArray" href="#CUDA.CuTextureArray"><code>CUDA.CuTextureArray</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuTextureArray{T,N}(undef, dims)</code></pre><p><code>N</code>-dimensional dense texture array with elements of type <code>T</code>. These arrays are optimized for texture fetching, and are only meant to be used as a source for <a href="#CUDA.CuTexture"><code>CuTexture{T,N,P}</code></a> objects.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Experimental API. Subject to change without deprecation.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/src/texture.jl#L14-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuTextureArray-Tuple{Any}" href="#CUDA.CuTextureArray-Tuple{Any}"><code>CUDA.CuTextureArray</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">CuTextureArray{T,N}(undef, dims)</code></pre><p>Construct an uninitialized texture array of <code>N</code> dimensions specified in the <code>dims</code> tuple, with elements of type <code>T</code>. Use <code>Base.copyto!</code> to initialize this texture array, or use constructors that take a non-texture array to do so automatically.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Experimental API. Subject to change without deprecation.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/src/texture.jl#L29-L38">source</a></section><section><div><pre><code class="nohighlight hljs">CuTextureArray(A::AbstractArray)</code></pre><p>Allocate and initialize a texture buffer from host memory in <code>A</code>.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Experimental API. Subject to change without deprecation.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/src/texture.jl#L68-L75">source</a></section><section><div><pre><code class="nohighlight hljs">CuTextureArray(A::CuArray)</code></pre><p>Allocate and initialize a texture buffer from device memory in <code>A</code>.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Experimental API. Subject to change without deprecation.</p></div></div></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/src/texture.jl#L82-L89">source</a></section></article><h2 id="Occupancy-API"><a class="docs-heading-anchor" href="#Occupancy-API">Occupancy API</a><a id="Occupancy-API-1"></a><a class="docs-heading-anchor-permalink" href="#Occupancy-API" title="Permalink"></a></h2><p>The occupancy API can be used to figure out an appropriate launch configuration for a compiled kernel (represented as a <code>CuFunction</code>) on the current device:</p><article class="docstring"><header><a class="docstring-binding" id="CUDA.launch_configuration" href="#CUDA.launch_configuration"><code>CUDA.launch_configuration</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">launch_configuration(fun::CuFunction; shmem=0, max_threads=0)</code></pre><p>Calculate a suggested launch configuration for kernel <code>fun</code> requiring <code>shmem</code> bytes of dynamic shared memory. Returns a tuple with a suggested amount of threads, and the minimal amount of blocks to reach maximal occupancy. Optionally, the maximum amount of threads can be constrained using <code>max_threads</code>.</p><p>In the case of a variable amount of shared memory, pass a callable object for <code>shmem</code> instead, taking a single integer representing the block size and returning the amount of dynamic shared memory for that configuration.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/occupancy.jl#L42-L53">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.active_blocks" href="#CUDA.active_blocks"><code>CUDA.active_blocks</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">active_blocks(fun::CuFunction, threads; shmem=0)</code></pre><p>Calculate the maximum number of active blocks per multiprocessor when running <code>threads</code> threads of a kernel <code>fun</code> requiring <code>shmem</code> bytes of dynamic shared memory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/occupancy.jl#L3-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.occupancy" href="#CUDA.occupancy"><code>CUDA.occupancy</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">occupancy(fun::CuFunction, threads; shmem=0)</code></pre><p>Calculate the theoretical occupancy of launching <code>threads</code> threads of a kernel <code>fun</code> requiring <code>shmem</code> bytes of dynamic shared memory.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/occupancy.jl#L15-L21">source</a></section></article><h2 id="Graph-Execution"><a class="docs-heading-anchor" href="#Graph-Execution">Graph Execution</a><a id="Graph-Execution-1"></a><a class="docs-heading-anchor-permalink" href="#Graph-Execution" title="Permalink"></a></h2><p>CUDA graphs can be easily recorded and executed using the high-level <code>@captured</code> macro:</p><article class="docstring"><header><a class="docstring-binding" id="CUDA.@captured" href="#CUDA.@captured"><code>CUDA.@captured</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">for ...
    @capture begin
        # code that executes several kernels or CUDA operations
    end
end</code></pre><p>A convenience macro for recording a graph of CUDA operations and automatically cache and update the execution. This can improve performance when executing kernels in a loop, where the launch overhead might dominate the execution.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>For this to be effective, the kernels and operations executed inside of the captured region should not signficantly change across iterations of the loop. It is allowed to, e.g., change kernel arguments or inputs to operations, as this will be processed by updating the cached executable graph. However, significant changes will result in an instantiation of the graph from scratch, which is an expensive operation.</p></div></div><p>See also: <a href="#CUDA.capture"><code>capture</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/graph.jl#L167-L187">source</a></section></article><p>Low-level operations are available too:</p><article class="docstring"><header><a class="docstring-binding" id="CUDA.CuGraph" href="#CUDA.CuGraph"><code>CUDA.CuGraph</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">CuGraph([flags])</code></pre><p>Create an empty graph for use with low-level graph operations. If you want to create a graph while directly recording operations, use <a href="#CUDA.capture"><code>capture</code></a>. For a high-level interface that also automatically executes the graph, use the <a href="#CUDA.@captured"><code>@captured</code></a> macro.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/graph.jl#L10-L16">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.capture" href="#CUDA.capture"><code>CUDA.capture</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">capture([flags], [throw_error::Bool=true]) do
    ...
end</code></pre><p>Capture a graph of CUDA operations. The returned graph can then be instantiated and executed repeatedly for improved performance.</p><p>Note that many operations, like initial kernel compilation or memory allocations, cannot be captured. To work around this, you can set the <code>throw_error</code> keyword to false, which will cause this function to return <code>nothing</code> if such a failure happens. You can then try to evaluate the function in a regular way, and re-record afterwards.</p><p>See also: <a href="#CUDA.instantiate"><code>instantiate</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/graph.jl#L54-L68">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.instantiate" href="#CUDA.instantiate"><code>CUDA.instantiate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">instantiate(graph::CuGraph)</code></pre><p>Creates an executable graph from a graph. This graph can then be launched, or updated with an other graph.</p><p>See also: <a href="#CUDA.launch"><code>launch</code></a>, <a href="#CUDA.update"><code>update</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/graph.jl#L104-L111">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.launch-Tuple{CuGraphExec}" href="#CUDA.launch-Tuple{CuGraphExec}"><code>CUDA.launch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">launch(f::CuFunction; args...; blocks::CuDim=1, threads::CuDim=1,
       cooperative=false, shmem=0, stream=stream())</code></pre><p>Low-level call to launch a CUDA function <code>f</code> on the GPU, using <code>blocks</code> and <code>threads</code> as respectively the grid and block configuration. Dynamic shared memory is allocated according to <code>shmem</code>, and the kernel is launched on stream <code>stream</code>.</p><p>Arguments to a kernel should either be bitstype, in which case they will be copied to the internal kernel parameter buffer, or a pointer to device memory.</p><p>This is a low-level call, prefer to use <a href="#CUDA.cudacall"><code>cudacall</code></a> instead.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/execution.jl#L39-L51">source</a></section><section><div><pre><code class="nohighlight hljs">launch(exec::CuGraphExec, [stream::CuStream])</code></pre><p>Launches an executable graph, by default in the currently-active stream.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/graph.jl#L120-L124">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="CUDA.update" href="#CUDA.update"><code>CUDA.update</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">update(exec::CuGraphExec, graph::CuGraph; [throw_error::Bool=true])</code></pre><p>Check whether an executable graph can be updated with a graph and perform the update if possible. Returns a boolean indicating whether the update was successful. Unless <code>throw_error</code> is set to false, also throws an error if the update failed.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaGPU/CUDA.jl/blob/edfbec6d9223af15634d5db597782f4ed7076d85/lib/cudadrv/graph.jl#L129-L135">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../api/array/">« Array programming</a><a class="docs-footer-nextpage" href="../../faq/">FAQ »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.7 on <span class="colophon-date" title="Tuesday 30 November 2021 11:52">Tuesday 30 November 2021</span>. Using Julia version 1.6.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
